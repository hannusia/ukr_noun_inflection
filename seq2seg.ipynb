{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../ukr_noun_inflection/data/train.csv\")[[\"base form\", \"concat form\",\"inflected form\", \"number\", \"case\"]]\n",
    "df_test = pd.read_csv(\"../ukr_noun_inflection/data/test.csv\")[[\"base form\", \"concat form\",\"inflected form\", \"number\", \"case\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19650, 5), (6592, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base form</th>\n",
       "      <th>concat form</th>\n",
       "      <th>inflected form</th>\n",
       "      <th>number</th>\n",
       "      <th>case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1N</td>\n",
       "      <td>автофура</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1G</td>\n",
       "      <td>автофури</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1D</td>\n",
       "      <td>автофурі</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1A</td>\n",
       "      <td>автофуру</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1I</td>\n",
       "      <td>автофурою</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1L</td>\n",
       "      <td>автофурі</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура1V</td>\n",
       "      <td>автофуро</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура2N</td>\n",
       "      <td>автофури</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура2G</td>\n",
       "      <td>автофур</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>автофура</td>\n",
       "      <td>автофура2D</td>\n",
       "      <td>автофурам</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  base form concat form inflected form  number case\n",
       "0  автофура  автофура1N       автофура       1    N\n",
       "1  автофура  автофура1G       автофури       1    G\n",
       "2  автофура  автофура1D       автофурі       1    D\n",
       "3  автофура  автофура1A       автофуру       1    A\n",
       "4  автофура  автофура1I      автофурою       1    I\n",
       "5  автофура  автофура1L       автофурі       1    L\n",
       "6  автофура  автофура1V       автофуро       1    V\n",
       "7  автофура  автофура2N       автофури       2    N\n",
       "8  автофура  автофура2G        автофур       2    G\n",
       "9  автофура  автофура2D      автофурам       2    D"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = []\n",
    "output = []\n",
    "inp_chars = set()\n",
    "out_chars = set()\n",
    "nb_samples = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19650/19650 [00:00<00:00, 22680.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process nouns\n",
    "for line in tqdm(range(nb_samples)):\n",
    "    row = df_train.iloc[line]\n",
    "    inp = row[\"concat form\"]\n",
    "    out = '\\t' + row[\"inflected form\"] + '\\n'\n",
    "    input.append(inp)\n",
    "    output.append(out)\n",
    "\n",
    "    for ch in inp:\n",
    "        if (ch not in inp_chars):\n",
    "            inp_chars.add(ch)\n",
    "    \n",
    "    for ch in out:\n",
    "        if (ch not in out_chars):\n",
    "            out_chars.add(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"' - 1 2 A D G I L N V а б в г д е ж з и й к л м н о п р с т у ф х ц ч ш щ ь ю я є і ї ґ\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_chars = sorted(list(out_chars))\n",
    "inp_chars = sorted(list(inp_chars))\n",
    "\n",
    "' '.join(inp_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each input character - key is index and value is character\n",
    "inp_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get input character given its index - key is character and value is index\n",
    "inp_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(inp_chars):\n",
    "    inp_index_to_char_dict[k] = v\n",
    "    inp_char_to_index_dict[v] = k\n",
    "\n",
    "\n",
    "# dictionary to index each output character - key is index and value is character\n",
    "out_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get output character given its index - key is character and value is index\n",
    "out_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(out_chars):\n",
    "    out_index_to_char_dict[k] = v\n",
    "    out_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_input = df_train[\"concat form\"].str.len().max() + 5\n",
    "max_len_output = df_train[\"inflected form\"].str.len().max() + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['inp_chars'] = inp_chars\n",
    "data['out_chars'] = out_chars\n",
    "data['max_len_input'] = max_len_input\n",
    "data['max_len_output'] = max_len_output\n",
    "data['inp_index_to_char_dict'] = inp_index_to_char_dict\n",
    "data['inp_char_to_index_dict'] = inp_char_to_index_dict\n",
    "data['out_index_to_char_dict'] = out_index_to_char_dict\n",
    "data['out_char_to_index_dict'] = out_char_to_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling data for inference model\n",
    "pickle.dump(data, open(\"data.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = np.zeros(shape = (nb_samples, max_len_input, len(inp_chars)), dtype='float32')\n",
    "tokenized_output = np.zeros(shape = (nb_samples, max_len_output, len(out_chars)), dtype='float32')\n",
    "target_data = np.zeros((nb_samples, max_len_output, len(out_chars)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19650/19650 [00:00<00:00, 72869.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize nouns\n",
    "for i in tqdm(range(nb_samples)):\n",
    "    for k,ch in enumerate(input[i]):\n",
    "        tokenized_input[i ,k, inp_char_to_index_dict[ch]] = 1\n",
    "\n",
    "    for k,ch in enumerate(output[i]):\n",
    "        tokenized_output[i, k, out_char_to_index_dict[ch]] = 1\n",
    "\n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i, k-1, out_char_to_index_dict[ch]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 23:02:39.344131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:02:39.345436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:02:39.346222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "encoder_input = Input(shape=(None, len(inp_chars)))\n",
    "encoder_LSTM = LSTM(256, return_state = True)\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 23:02:41.354208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:02:41.355276: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:02:41.356152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Decoder model\n",
    "decoder_input = Input(shape=(None, len(out_chars)))\n",
    "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(out_chars), activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 23:02:45.510489: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:02:45.512138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:02:45.513077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 23:02:45.690005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:02:45.691493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:02:45.692706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 23:02:46.396927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:02:46.398456: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:02:46.399511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 23:02:46.561761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:02:46.562831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:02:46.563792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 23:03:17.932665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:03:17.933885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:03:17.935165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 23:03:18.093397: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:03:18.094533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:03:18.095655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 36s - loss: 1.2046 - accuracy: 0.0548 - val_loss: 1.1854 - val_accuracy: 0.0583 - 36s/epoch - 145ms/step\n",
      "Epoch 2/50\n",
      "246/246 - 33s - loss: 1.1768 - accuracy: 0.0613 - val_loss: 1.1761 - val_accuracy: 0.0636 - 33s/epoch - 132ms/step\n",
      "Epoch 3/50\n",
      "246/246 - 30s - loss: 1.1609 - accuracy: 0.0656 - val_loss: 1.1528 - val_accuracy: 0.0705 - 30s/epoch - 123ms/step\n",
      "Epoch 4/50\n",
      "246/246 - 30s - loss: 1.1430 - accuracy: 0.0711 - val_loss: 1.1729 - val_accuracy: 0.0618 - 30s/epoch - 122ms/step\n",
      "Epoch 5/50\n",
      "246/246 - 32s - loss: 1.1180 - accuracy: 0.0789 - val_loss: 1.1494 - val_accuracy: 0.0686 - 32s/epoch - 129ms/step\n",
      "Epoch 6/50\n",
      "246/246 - 34s - loss: 1.0955 - accuracy: 0.0864 - val_loss: 1.0979 - val_accuracy: 0.0887 - 34s/epoch - 140ms/step\n",
      "Epoch 7/50\n",
      "246/246 - 22s - loss: 1.0728 - accuracy: 0.0942 - val_loss: 1.0920 - val_accuracy: 0.0917 - 22s/epoch - 90ms/step\n",
      "Epoch 8/50\n",
      "246/246 - 27s - loss: 1.0433 - accuracy: 0.1032 - val_loss: 1.0593 - val_accuracy: 0.0979 - 27s/epoch - 111ms/step\n",
      "Epoch 9/50\n",
      "246/246 - 34s - loss: 1.0178 - accuracy: 0.1113 - val_loss: 1.0455 - val_accuracy: 0.1056 - 34s/epoch - 137ms/step\n",
      "Epoch 10/50\n",
      "246/246 - 25s - loss: 0.9938 - accuracy: 0.1193 - val_loss: 1.0351 - val_accuracy: 0.1095 - 25s/epoch - 102ms/step\n",
      "Epoch 11/50\n",
      "246/246 - 32s - loss: 0.9691 - accuracy: 0.1266 - val_loss: 1.0225 - val_accuracy: 0.1097 - 32s/epoch - 130ms/step\n",
      "Epoch 12/50\n",
      "246/246 - 34s - loss: 0.9435 - accuracy: 0.1359 - val_loss: 1.0151 - val_accuracy: 0.1165 - 34s/epoch - 138ms/step\n",
      "Epoch 13/50\n",
      "246/246 - 26s - loss: 0.9176 - accuracy: 0.1422 - val_loss: 1.0038 - val_accuracy: 0.1147 - 26s/epoch - 106ms/step\n",
      "Epoch 14/50\n",
      "246/246 - 33s - loss: 0.8895 - accuracy: 0.1511 - val_loss: 0.9938 - val_accuracy: 0.1017 - 33s/epoch - 135ms/step\n",
      "Epoch 15/50\n",
      "246/246 - 33s - loss: 0.8619 - accuracy: 0.1589 - val_loss: 0.9759 - val_accuracy: 0.1250 - 33s/epoch - 134ms/step\n",
      "Epoch 16/50\n",
      "246/246 - 33s - loss: 0.8342 - accuracy: 0.1673 - val_loss: 0.9818 - val_accuracy: 0.1180 - 33s/epoch - 134ms/step\n",
      "Epoch 17/50\n",
      "246/246 - 35s - loss: 0.8064 - accuracy: 0.1769 - val_loss: 0.9731 - val_accuracy: 0.1077 - 35s/epoch - 143ms/step\n",
      "Epoch 18/50\n",
      "246/246 - 37s - loss: 0.7784 - accuracy: 0.1885 - val_loss: 0.9586 - val_accuracy: 0.1338 - 37s/epoch - 151ms/step\n",
      "Epoch 19/50\n",
      "246/246 - 28s - loss: 0.7518 - accuracy: 0.1979 - val_loss: 0.9455 - val_accuracy: 0.1312 - 28s/epoch - 112ms/step\n",
      "Epoch 20/50\n",
      "246/246 - 30s - loss: 0.7255 - accuracy: 0.2063 - val_loss: 0.9538 - val_accuracy: 0.1365 - 30s/epoch - 123ms/step\n",
      "Epoch 21/50\n",
      "246/246 - 26s - loss: 0.6986 - accuracy: 0.2170 - val_loss: 0.9429 - val_accuracy: 0.1359 - 26s/epoch - 106ms/step\n",
      "Epoch 22/50\n",
      "246/246 - 24s - loss: 0.6733 - accuracy: 0.2273 - val_loss: 0.9351 - val_accuracy: 0.1350 - 24s/epoch - 98ms/step\n",
      "Epoch 23/50\n",
      "246/246 - 34s - loss: 0.6486 - accuracy: 0.2356 - val_loss: 0.9447 - val_accuracy: 0.1405 - 34s/epoch - 137ms/step\n",
      "Epoch 24/50\n",
      "246/246 - 30s - loss: 0.6284 - accuracy: 0.2417 - val_loss: 0.9374 - val_accuracy: 0.1399 - 30s/epoch - 121ms/step\n",
      "Epoch 25/50\n",
      "246/246 - 26s - loss: 0.6041 - accuracy: 0.2507 - val_loss: 0.9421 - val_accuracy: 0.1389 - 26s/epoch - 107ms/step\n",
      "Epoch 26/50\n",
      "246/246 - 37s - loss: 0.5865 - accuracy: 0.2575 - val_loss: 0.9492 - val_accuracy: 0.1362 - 37s/epoch - 150ms/step\n",
      "Epoch 27/50\n",
      "246/246 - 37s - loss: 0.5711 - accuracy: 0.2627 - val_loss: 0.9486 - val_accuracy: 0.1416 - 37s/epoch - 152ms/step\n",
      "Epoch 28/50\n",
      "246/246 - 37s - loss: 0.5520 - accuracy: 0.2701 - val_loss: 0.9460 - val_accuracy: 0.1428 - 37s/epoch - 152ms/step\n",
      "Epoch 29/50\n",
      "246/246 - 24s - loss: 0.5357 - accuracy: 0.2754 - val_loss: 0.9483 - val_accuracy: 0.1413 - 24s/epoch - 98ms/step\n",
      "Epoch 30/50\n",
      "246/246 - 25s - loss: 0.5218 - accuracy: 0.2795 - val_loss: 0.9411 - val_accuracy: 0.1437 - 25s/epoch - 103ms/step\n",
      "Epoch 31/50\n",
      "246/246 - 35s - loss: 0.5102 - accuracy: 0.2830 - val_loss: 0.9431 - val_accuracy: 0.1468 - 35s/epoch - 142ms/step\n",
      "Epoch 32/50\n",
      "246/246 - 33s - loss: 0.4983 - accuracy: 0.2869 - val_loss: 0.9389 - val_accuracy: 0.1508 - 33s/epoch - 134ms/step\n",
      "Epoch 33/50\n",
      "246/246 - 34s - loss: 0.4854 - accuracy: 0.2907 - val_loss: 0.9512 - val_accuracy: 0.1456 - 34s/epoch - 136ms/step\n",
      "Epoch 34/50\n",
      "246/246 - 30s - loss: 0.4755 - accuracy: 0.2933 - val_loss: 0.9485 - val_accuracy: 0.1460 - 30s/epoch - 121ms/step\n",
      "Epoch 35/50\n",
      "246/246 - 14s - loss: 0.4662 - accuracy: 0.2959 - val_loss: 0.9523 - val_accuracy: 0.1458 - 14s/epoch - 57ms/step\n",
      "Epoch 36/50\n",
      "246/246 - 14s - loss: 0.4585 - accuracy: 0.2975 - val_loss: 0.9507 - val_accuracy: 0.1490 - 14s/epoch - 57ms/step\n",
      "Epoch 37/50\n",
      "246/246 - 14s - loss: 0.4493 - accuracy: 0.2999 - val_loss: 0.9524 - val_accuracy: 0.1470 - 14s/epoch - 57ms/step\n",
      "Epoch 38/50\n",
      "246/246 - 14s - loss: 0.4404 - accuracy: 0.3023 - val_loss: 0.9580 - val_accuracy: 0.1475 - 14s/epoch - 57ms/step\n",
      "Epoch 39/50\n",
      "246/246 - 15s - loss: 0.4339 - accuracy: 0.3041 - val_loss: 0.9684 - val_accuracy: 0.1450 - 15s/epoch - 59ms/step\n",
      "Epoch 40/50\n",
      "246/246 - 14s - loss: 0.4277 - accuracy: 0.3057 - val_loss: 0.9542 - val_accuracy: 0.1503 - 14s/epoch - 59ms/step\n",
      "Epoch 41/50\n",
      "246/246 - 15s - loss: 0.4216 - accuracy: 0.3072 - val_loss: 0.9507 - val_accuracy: 0.1500 - 15s/epoch - 61ms/step\n",
      "Epoch 42/50\n",
      "246/246 - 15s - loss: 0.4146 - accuracy: 0.3085 - val_loss: 0.9558 - val_accuracy: 0.1506 - 15s/epoch - 60ms/step\n",
      "Epoch 43/50\n",
      "246/246 - 14s - loss: 0.4115 - accuracy: 0.3094 - val_loss: 0.9525 - val_accuracy: 0.1502 - 14s/epoch - 59ms/step\n",
      "Epoch 44/50\n",
      "246/246 - 15s - loss: 0.4066 - accuracy: 0.3103 - val_loss: 0.9523 - val_accuracy: 0.1493 - 15s/epoch - 60ms/step\n",
      "Epoch 45/50\n",
      "246/246 - 15s - loss: 0.4022 - accuracy: 0.3115 - val_loss: 0.9559 - val_accuracy: 0.1485 - 15s/epoch - 60ms/step\n",
      "Epoch 46/50\n",
      "246/246 - 15s - loss: 0.3983 - accuracy: 0.3123 - val_loss: 0.9518 - val_accuracy: 0.1524 - 15s/epoch - 59ms/step\n",
      "Epoch 47/50\n",
      "246/246 - 15s - loss: 0.3968 - accuracy: 0.3126 - val_loss: 0.9535 - val_accuracy: 0.1508 - 15s/epoch - 61ms/step\n",
      "Epoch 48/50\n",
      "246/246 - 15s - loss: 0.3906 - accuracy: 0.3139 - val_loss: 0.9578 - val_accuracy: 0.1511 - 15s/epoch - 61ms/step\n",
      "Epoch 49/50\n",
      "246/246 - 15s - loss: 0.3856 - accuracy: 0.3153 - val_loss: 0.9559 - val_accuracy: 0.1497 - 15s/epoch - 60ms/step\n",
      "Epoch 50/50\n",
      "246/246 - 15s - loss: 0.3853 - accuracy: 0.3150 - val_loss: 0.9655 - val_accuracy: 0.1505 - 15s/epoch - 63ms/step\n",
      "CPU times: user 2h 8min 1s, sys: 10min 55s, total: 2h 18min 57s\n",
      "Wall time: 21min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30f8388790>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(x=[tokenized_input, tokenized_output], \n",
    "          y=target_data,\n",
    "          batch_size=64,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          #callbacks=callbacks_list,\n",
    "         verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq, encoder_model_inf, decoder_model_inf):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(out_chars)))\n",
    "    target_seq[0, 0, out_char_to_index_dict['\\t']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    prob = 1.0\n",
    "    while not stop_condition:\n",
    "        \n",
    "        #decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #predict_pr = decoder_model_inf.predict_proba(x=[target_seq] + states_val)\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #print(decoder_out)\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        max_val = np.max(decoder_out[0,-1,:])\n",
    "        prob *= max_val\n",
    "        sampled_fra_char = out_index_to_char_dict[max_val_index]\n",
    "        translated_sent += sampled_fra_char\n",
    "        print('{} == {}'.format(sampled_fra_char,max_val))\n",
    "        \n",
    "        if ( (sampled_fra_char == '\\n') or (len(translated_sent) > max_len_output)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(out_chars)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "    \n",
    "    prob = prob**(1/len(translated_sent))\n",
    "    return translated_sent, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 23:30:06.297794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 23:30:06.298692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 23:30:06.299402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(seq):\n",
    "    tokenized_eng_sentence = np.zeros(shape = (1, max_len_input, len(inp_chars)), dtype='float32')\n",
    "    for k,ch in enumerate(seq):\n",
    "        tokenized_eng_sentence[0, k, inp_char_to_index_dict[ch]] = 1\n",
    "        \n",
    "    return tokenized_eng_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "і == 0.8185333609580994\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "к == 0.6298231482505798\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "к == 0.13716712594032288\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "і == 0.06030400097370148\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "\n",
      " == 0.06717141717672348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19561724404877676"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = 'кіт1G'\n",
    "inp_seq = tokenize(inp)\n",
    "translated_sent, prob = decode_seq(inp_seq, encoder_model_inf, decoder_model_inf)\n",
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "166e9bb9428cb8553d92c53cc1350464430c4f0313216e49bffe4fb44b7aba21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
